{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History\n",
    "\n",
    "## Test with and without scaling\n",
    "- Clean and (vanilla) StandardScaler() min_interval=20 => 0.63142 (less than without scaling/Cleaning) overfit test set?\n",
    "  - 0.9670995670995671 On the reduce_test_set \n",
    "  \n",
    "- Clean min_interval=20 => 0.63142... Same?  (normal, in random forest it is *useless*)\n",
    "  - 0.9783549783549783 On the reduce_test_set \n",
    "\n",
    "## Params \n",
    "- Grid_search \"classify__n_estimator\": [3, 10, 30], \"classify__min_interval\": [3, 5, 10]}\n",
    "\n",
    "## Same nÂ° of classes (yay)\n",
    "\n",
    "## Not enough tunable parameters in sktime lets do our own model\n",
    "- Give quite good score (window=16) (less than sktime but still good): 0.9714285714285714 (Better score on Kaggle !!!) - give much more better result by removing nAN (0.73 on kaggle)\n",
    "- Perform better than a *naive* randomForest given X_train_reduce/Y_train_reduce: 0.9428571428571428\n",
    "- On the reduce test set having a window=4 give *worst result:* 0.9506493506493506\n",
    "- Time series model perform better \n",
    "\n",
    "## Leave one out group => more accurate according to the test set than using typical grid search\n",
    "## Worst result but more accurate\n",
    "## No nan o test set, can do better preprocess by doing the median only on the same calss\n",
    "## Trying with takeing the median for a given class but perform quite bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sktime.classification.compose import ColumnEnsembleClassifier\n",
    "from sktime.classification.dictionary_based import BOSSEnsemble\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.transformations.panel.compose import ColumnConcatenator\n",
    "from python.utils import load_data\n",
    "from python.preprocess import TimeSerieMaker, CleanNanByMedian, SimpleSlidingWindowFeaturesExtractor\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sktime.datatypes._panel._convert import (\n",
    "    from_3d_numpy_to_nested,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from python.model_selection import crossValidationOneOut, GridSearchGroup\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: (3500, 15872).\n",
      "y_train size: (3500,).\n",
      "X_test size: (3500, 15872).\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'data'\n",
    "X_train, y_train, X_test, subjects = load_data(DATA_PATH)\n",
    "X_train = SimpleImputer(missing_values=-999999.99, strategy=\"median\").fit_transform(X_train) # take the median instead of Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduce, X_test_reduce, y_train_reduce, y_test_reduce = train_test_split(X_train, y_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = Pipeline([\n",
    "    (\"std_scaler\", StandardScaler()),\n",
    "    (\"sswfe\", SimpleSlidingWindowFeaturesExtractor(window_size=16)),\n",
    "    (\"rnf_cls\", RandomForestClassifier(random_state=42, n_estimators=200))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipeline_own_knn = Pipeline([\n",
    "    (\"std_scaler\", StandardScaler()),\n",
    "    (\"sswfe\", SimpleSlidingWindowFeaturesExtractor(window_size=16)),\n",
    "    (\"rnf_cls\", KNeighborsClassifier( n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline_own_log = Pipeline([\n",
    "    (\"std_scaler\", StandardScaler()),\n",
    "    (\"sswfe\", SimpleSlidingWindowFeaturesExtractor(window_size=16)),\n",
    "    (\"rnf_cls\", LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_own_rf = Pipeline([\n",
    "    (\"std_scaler\", StandardScaler()),\n",
    "    (\"sswfe\", SimpleSlidingWindowFeaturesExtractor(window_size=16)),\n",
    "    (\"rnf_cls\", RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = Pipeline([\n",
    "    (\"std_scaler\", StandardScaler()),\n",
    "    (\"sswfe\", SimpleSlidingWindowFeaturesExtractor(window_size=16)),\n",
    "    (\"vot\", VotingClassifier(\n",
    "        estimators=[(\"lr\",LogisticRegression()),\n",
    "                    (\"rnf\", RandomForestClassifier(random_state=42, n_estimators=200, max_features=2, bootstrap=False, max_depth=80)),\n",
    "                    (\"knn\", KNeighborsClassifier(n_jobs=-1))], \n",
    "        voting=\"soft\"\n",
    "    )) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_concatenator = [\n",
    "    (\"std_scaler\", StandardScaler()),\n",
    "    (\"time-serie\", TimeSerieMaker()),\n",
    "    (\"concatenate\", ColumnConcatenator()),\n",
    "    (\"classify\", TimeSeriesForestClassifier(n_estimators=20, random_state=42, n_jobs=-1, min_interval=3)),\n",
    "]\n",
    "\n",
    "time_serie_forest_clf = Pipeline(column_concatenator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\"rnf_cls__n_estimators\": [150], \"rnf_cls__max_features\": [2, 4, \"auto\"], 'rnf_cls__bootstrap': [True, False], 'rnf_cls__max_depth': [5, 8, 15, 25], \"sswfe__window_size\": [16, 32]}\n",
    "]\n",
    "\n",
    "gsg = GridSearchGroup(pipeline_own_rf, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsg.fit(X_train, y_train, subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_test_score': 0.5116985352555026, 'params': (200, 2, True, 110)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvres = gsg._cv_results\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('std_scaler', StandardScaler()),\n",
       "                ('sswfe', SimpleSlidingWindowFeaturesExtractor(window_size=16)),\n",
       "                ('rnf_cls',\n",
       "                 RandomForestClassifier(max_features=4, n_estimators=200,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_own_rf.fit(X_train, y_train) # best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9645021645021645"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_test_reduce, y_test_reduce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0.78,\n",
    " 0.5783475783475783,\n",
    " 0.6802197802197802,\n",
    " 0.4087237479806139,\n",
    " 0.6692056583242655]\n",
    "\n",
    "[0.8085714285714286,\n",
    " 0.6951566951566952,\n",
    " 0.4989010989010989,\n",
    " 0.518578352180937,\n",
    " 0.5614798694232862]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8085714285714286,\n",
       " 0.6951566951566952,\n",
       " 0.4989010989010989,\n",
       " 0.518578352180937,\n",
       " 0.5614798694232862]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidationOneOut(X_train, y_train, pipeline_own_rf, subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_serie_forest_clf.fit(X_train_reduce, y_train_reduce) # sktime (perform worst on kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9774891774891775"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_serie_forest_clf.score(X_test_reduce, y_test_reduce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = pipeline_own_rf\n",
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission toy_submission.csv saved in submissions/toy_submission.csv.\n"
     ]
    }
   ],
   "source": [
    "from python.utils import write_submission\n",
    "\n",
    "write_submission(y_pred, 'submissions')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab506c54e6c17d8f79536a2d17ae8efc1e1832069b7e1017a1d4a6cb95708c0f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('AI': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
